{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Python/2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from Project.dataStructures import *\n",
    "from Project.manageDataset import *\n",
    "from Project.dataStructures import *\n",
    "from Project.dataStructures import get_data_target_lists\n",
    "from Project.launchAlgorithms import *\n",
    "from Project.utilities import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import PReLU, Dense, Activation,BatchNormalization,Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdm = np.random.RandomState()\n",
    "rdm.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasetList, attributes, coloumns = read_file('/dataset.csv')\n",
    "targetsDic, targets = get_classes(coloumns['class'])\n",
    "dataset = string_to_float(switch_label(datasetList, targets))\n",
    "rdm.shuffle(dataset)\n",
    "labels = []\n",
    "for item in dataset:\n",
    "    labels.append(item[-1])  \n",
    "stringLabels = [targets[item-1] for item in labels]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(dataset)[:,:len(dataset[0])-1].astype(np.float32)\n",
    "Y = np.array(dataset)[:,len(dataset[0])-1].astype(np.int32)\n",
    "Y = np.array([item-1 for item in Y])\n",
    "xTrain, xTest = X[:int(999*0.8)], X[int(999*0.8):]\n",
    "yTrain, yTest = Y[:int(999*0.8)], Y[int(999*0.8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "xTrain = scaler.fit_transform(xTrain)\n",
    "xTest = scaler.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Dense(50, input_dim=len(xTrain[0]),init='he_normal'), PReLU(), BatchNormalization(), Dropout(0.2),\n",
    "    Dense(10, init='he_uniform'), Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for layer in layers:\n",
    "    model.add(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.293 - Train Acc: 13.892 - Test Acc: 17.910\n",
      "Loss: 2.213 - Train Acc: 24.155 - Test Acc: 21.891\n",
      "Loss: 2.091 - Train Acc: 31.289 - Test Acc: 34.826\n",
      "Loss: 1.923 - Train Acc: 39.800 - Test Acc: 39.801\n",
      "Loss: 1.745 - Train Acc: 44.806 - Test Acc: 42.786\n",
      "Loss: 1.585 - Train Acc: 47.309 - Test Acc: 45.274\n",
      "Loss: 1.469 - Train Acc: 50.814 - Test Acc: 50.249\n",
      "Loss: 1.371 - Train Acc: 53.942 - Test Acc: 47.761\n",
      "Loss: 1.300 - Train Acc: 60.826 - Test Acc: 56.716\n",
      "Loss: 1.243 - Train Acc: 61.577 - Test Acc: 57.711\n",
      "Loss: 1.192 - Train Acc: 64.581 - Test Acc: 59.701\n",
      "Loss: 1.143 - Train Acc: 64.205 - Test Acc: 56.219\n",
      "Loss: 1.115 - Train Acc: 65.707 - Test Acc: 61.194\n",
      "Loss: 1.087 - Train Acc: 66.708 - Test Acc: 61.692\n",
      "Loss: 1.066 - Train Acc: 67.835 - Test Acc: 63.682\n",
      "Loss: 1.022 - Train Acc: 66.583 - Test Acc: 59.204\n",
      "Loss: 1.018 - Train Acc: 68.836 - Test Acc: 63.184\n",
      "Loss: 0.989 - Train Acc: 67.835 - Test Acc: 61.194\n",
      "Loss: 0.978 - Train Acc: 70.213 - Test Acc: 64.179\n",
      "Loss: 0.969 - Train Acc: 68.335 - Test Acc: 57.711\n",
      "Loss: 0.946 - Train Acc: 67.835 - Test Acc: 62.687\n",
      "Loss: 0.934 - Train Acc: 70.964 - Test Acc: 64.677\n",
      "Loss: 0.926 - Train Acc: 72.340 - Test Acc: 67.164\n",
      "Loss: 0.908 - Train Acc: 71.214 - Test Acc: 64.179\n",
      "Loss: 0.901 - Train Acc: 71.214 - Test Acc: 65.174\n",
      "Loss: 0.889 - Train Acc: 71.965 - Test Acc: 65.174\n",
      "Loss: 0.867 - Train Acc: 73.592 - Test Acc: 66.169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-423eeda005bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    718\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laneskij/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    losses = []\n",
    "    for x_batch,y_batch in get_minibatches(xTrain,yTrain):\n",
    "        loss = model.train_on_batch(x_batch,y_batch)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    train_acc = 0.\n",
    "    for x_batch,y_batch in get_minibatches(xTrain,yTrain):\n",
    "        train_acc += (np.argmax(model.predict(x_batch), axis=1) == y_batch[:,0]).sum()\n",
    "    test_acc = 0.\n",
    "    for x_batch,y_batch in get_minibatches(xTest,yTest):\n",
    "        test_acc += (np.argmax(model.predict(x_batch), axis=1) == y_batch[:,0]).sum()\n",
    "        \n",
    "    print 'Loss: %.3f - Train Acc: %.3f - Test Acc: %.3f' % (np.mean(losses), 100.*train_acc/len(yTrain),100.*test_acc/len(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Dense(50, input_dim=len(xTrain[0]),init='he_normal'), PReLU(), Dropout(0.2), #BatchNormalization(), \n",
    "    Dense(20, init='he_normal'), PReLU(), Dropout(0.2),\n",
    "    Dense(50, init='he_normal'), PReLU(),\n",
    "    Dense(len(xTrain[0]), 'he_uniform'),Activation('sigmoid')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae = Sequential()\n",
    "for layer in layers:\n",
    "    ae.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae.compile(loss='binary_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.52384\n",
      "-6.28715\n",
      "-6.24408\n",
      "-6.54344\n",
      "-6.16925\n",
      "-6.26607\n",
      "-6.31527\n",
      "-6.30145\n",
      "-6.26018\n",
      "-6.39927\n",
      "-6.23213\n",
      "-6.2426\n",
      "-6.38079\n",
      "-6.49266\n",
      "-6.53403\n",
      "-6.46514\n",
      "-6.22063\n",
      "-6.46159\n",
      "-6.28227\n",
      "-6.28741\n",
      "-6.30933\n",
      "-6.30944\n",
      "-6.26362\n",
      "-6.35077\n",
      "-6.32898\n",
      "-6.51234\n",
      "-6.41488\n",
      "-6.44393\n",
      "-6.32946\n",
      "-6.1787\n",
      "-6.40876\n",
      "-6.21417\n",
      "-6.33956\n",
      "-6.59255\n",
      "-6.16513\n",
      "-6.38882\n",
      "-6.293\n",
      "-6.47128\n",
      "-6.01663\n",
      "-6.46239\n",
      "-6.23547\n",
      "-6.31212\n",
      "-6.39921\n",
      "-6.36226\n",
      "-6.24814\n",
      "-6.38934\n",
      "-6.22799\n",
      "-6.50863\n",
      "-6.47622\n",
      "-6.48242\n",
      "-6.44334\n",
      "-6.33062\n",
      "-6.48736\n",
      "-6.43973\n",
      "-6.47357\n",
      "-6.54657\n",
      "-6.27299\n",
      "-6.21739\n",
      "-6.44638\n",
      "-6.30953\n",
      "-6.25796\n",
      "-6.26687\n",
      "-6.45796\n",
      "-6.44663\n",
      "-6.10326\n",
      "-6.23155\n",
      "-6.32096\n",
      "-6.37618\n",
      "-6.32622\n",
      "-6.31378\n",
      "-6.27142\n",
      "-6.26681\n",
      "-6.31353\n",
      "-6.27322\n",
      "-6.33339\n",
      "-6.27624\n",
      "-6.58923\n",
      "-6.39704\n",
      "-6.38665\n",
      "-6.44043\n",
      "-6.32917\n",
      "-6.48509\n",
      "-6.27438\n",
      "-6.24405\n",
      "-6.66911\n",
      "-6.39949\n",
      "-6.44561\n",
      "-6.59397\n",
      "-6.28255\n",
      "-6.36048\n",
      "-6.38685\n",
      "-6.48742\n",
      "-6.38326\n",
      "-6.20546\n",
      "-6.60848\n",
      "-6.42267\n",
      "-6.2899\n",
      "-6.35908\n",
      "-6.53971\n",
      "-6.52452\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    losses = []\n",
    "    for xBatch,yBatch in get_minibatches(X,Y):\n",
    "        loss = ae.train_on_batch(xBatch,xBatch)\n",
    "        losses.append(loss)\n",
    "    print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding = K.function([ae.layers[0].input, 0], [ae.layers[3].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newX = []\n",
    "stringLabels = [targets[item-1] for item in labels]\n",
    "outputX = embedding([X])[0]\n",
    "for item in outputX:\n",
    "    newX.append(item)\n",
    "\n",
    "dataset = np.c_[np.array(newX), np.array(stringLabels)].tolist() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('encodedDataset' + '.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
